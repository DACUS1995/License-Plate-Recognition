{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms as T\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import string\n",
    "from typing import Tuple\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, root_path, type=\"train\"):\n",
    "\t\tself.root_path = root_path\n",
    "\t\tself.type = type\n",
    "\t\tself.images_paths = list(pathlib.Path(self.root_path + \"./images\").glob('*.png'))\n",
    "\t\tself.transforms = {\n",
    "\t\t\t'train' : T.Compose([\n",
    "\t\t\t\tT.ToTensor()\n",
    "\t\t\t]),\n",
    "\t\t\t'valid' : T.Compose([\n",
    "\t\t\t\tT.ToTensor()\n",
    "\t\t\t])\n",
    "\t\t}\n",
    "\t\tself.alphabet = string.ascii_letters + string.digits\n",
    "\t\tself.alphabet_size = len(self.alphabet)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage_path = self.images_paths[idx]\n",
    "\t\tsample_name = str(image_path).split(os.sep)[-1].split(\".\")[0]\n",
    "\t\ttext_path = self.root_path + \"/transcripts/\" + sample_name + \".txt\"\n",
    "\n",
    "\t\timage = Image.open(image_path).convert(\"RGB\")\n",
    "\t\twith open(text_path) as f:\n",
    "\t\t\ttext = f.read()\n",
    "\n",
    "\t\timage = self.transforms[self.type](image)\n",
    "\t\ttext = self.wordToTensor(text)\n",
    "\t\treturn image, text\n",
    "\t\t\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.images_paths)\n",
    "\n",
    "\tdef letterToIndex(self, letter):\n",
    "\t\treturn self.alphabet.find(letter)\n",
    "\n",
    "\tdef letterToTensor(self, letter):\n",
    "\t\ttensor = torch.zeros(1, n_letters)\n",
    "\t\ttensor[0][letterToIndex(letter)] = 1\n",
    "\t\treturn tensor\n",
    "\n",
    "\tdef wordToTensor(self, word):\n",
    "\t\ttensor = torch.zeros(len(word), 1, self.alphabet_size)\n",
    "\t\tfor li, letter in enumerate(word):\n",
    "\t\t\ttensor[li][0][self.letterToIndex(letter)] = 1\n",
    "\t\treturn tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "\tdef __init__(self, run_config):\n",
    "\t\tself._training_dataset = None\n",
    "\t\tself._validation_dataset = None\n",
    "\t\tself._run_config = run_config\n",
    "\n",
    "\t\tself._load_datasets()\n",
    "\t\t\n",
    "\tdef _load_datasets(self):\n",
    "\t\tself._training_dataset = CustomDataset(\"dataset/training\")\n",
    "\t\tself._validation_dataset = CustomDataset(\"dataset/validation\")\n",
    "\n",
    "\tdef get_data_loaders(self) -> Tuple[DataLoader]:\n",
    "\t\treturn (\n",
    "\t\t\tDataLoader(self._training_dataset, batch_size=self._run_config[\"batch_size\"], shuffle=True, num_workers=self._run_config[\"workers\"], pin_memory=True), \n",
    "\t\t\tDataLoader(self._validation_dataset, batch_size=self._run_config[\"batch_size\"], shuffle=True, num_workers=self._run_config[\"workers\"], pin_memory=True)\n",
    "\t\t)\n",
    "\n",
    "\tdef get_datasets(self) -> Tuple[Dataset]:\n",
    "\t\treturn self._training_dataset, self._validation_dataset\n",
    "\n",
    "\tdef get_datasets_sizes(self) -> Tuple[int]:\n",
    "\t\treturn len(self._training_dataset), len(self._validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "WORKERS = 1\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler(run_config = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"workers\": WORKERS\n",
    "})\n",
    "train_loader, validation_loader = data_handler.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscribeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TranscribeModel()\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.0001, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-08, \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "loss_criterion = nn.CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\tprint('Epoch {}/{}'.format(epoch, run.num_epochs))\n",
    "\tprint('-' * 10)\n",
    "\n",
    "\t########### Training step ###########\n",
    "\tmodel.train()\n",
    "\ttraining_loss = []\n",
    "\trunning_loss = 0.0\n",
    "\trunning_corrects = 0\n",
    "\t\t\t\n",
    "\tfor i, data in enumerate(tqdm(train_loader, desc=f\"Epoch [{epoch + 1}] progress\")):\n",
    "\n",
    "\t\tx_batch, label_batch = data\n",
    "\t\tx_batch, label_batch = x_batch.to(device), label_batch.to(device)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(x_batch)\n",
    "\t\t_, preds = torch.max(outputs, 1)\n",
    "\n",
    "\t\tloss = loss_criterion(outputs, label_batch)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\t\t# statistics\n",
    "\t\trunning_loss += loss.item() * x_batch.size(0)\n",
    "\t\trunning_corrects += torch.sum(preds == label_batch.detach())\n",
    "\t\ttraining_loss.append(loss.item())\n",
    "\n",
    "\tepoch_loss = running_loss / training_dataset_size\n",
    "\tepoch_acc = running_corrects.double() / training_dataset_size\n",
    "\n",
    "\t# tensorboard logging\n",
    "\twriter.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "\twriter.add_scalar(\"Accuracy/train\", epoch_acc, epoch)\n",
    "\n",
    "\tprint('Training step => Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "\t\tepoch_loss, epoch_acc\n",
    "\t))\n",
    "\n",
    "\tscheduler.step(epoch_acc)\n",
    "\n",
    "\n",
    "\t########### Validation step ###########\n",
    "\tmodel.eval()\n",
    "\tvalidation_loss = []\n",
    "\trunning_loss = 0.0\n",
    "\trunning_corrects = 0\n",
    "\n",
    "\tfor i, data in enumerate(validation_loader):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tx_batch, label_batch = data\n",
    "\t\t\tx_batch, label_batch = x_batch.to(device), label_batch.to(device)\n",
    "\n",
    "\t\t\toutputs = model(x_batch)\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\tloss = loss_criterion(...)\n",
    "\n",
    "\t\t\trunning_loss += loss.item() * x_batch.size(0)\n",
    "\t\t\trunning_corrects += torch.sum(preds == label_batch.detach())\n",
    "\t\t\tvalidation_loss.append(loss.item())\n",
    "\t\t\t\n",
    "\tepoch_loss = running_loss / validation_dataset_size\n",
    "\tepoch_acc = running_corrects.double() / validation_dataset_size\n",
    "\n",
    "\t# tensorboard logging\n",
    "\twriter.add_scalar(\"Loss/validation\", epoch_loss, epoch)\n",
    "\twriter.add_scalar(\"Accuracy/validation\", epoch_acc, epoch)\n",
    "\n",
    "\tprint('Evaluation step => Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "\t\tepoch_loss, epoch_acc\n",
    "\t))\n",
    "\n",
    "\t#Save the best model based on accuracy\n",
    "\tif epoch_acc > best_acc:\n",
    "\t\tbest_acc = epoch_acc\n",
    "\t\tbest_config = f\"{run}\"\n",
    "\t\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\t#Checkpoint\n",
    "\ttorch.save({\n",
    "\t\t\"epoch\": epoch,\n",
    "\t\t\"model_state_dict\": model.state_dict(),\n",
    "\t\t\"optimizer_state_dict\": optimizer.state_dict()\n",
    "\t}, \"./checkpoints/ckp.pt\")\n",
    "\n",
    "\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "\ttime_elapsed // 60, time_elapsed % 60\n",
    "))\n",
    "print('Best (so far) validation Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "print('-' * 10)\n",
    "print('### Final results ###\\n')\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "model.load_state_dict(best_model_wts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "97c67d8e0382c833d1d7ff2aaf3d36bcbf66720dd18abf32e81be90b4a114af6"
    }
   }
  },
  "language_info": {
   "name": "",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}