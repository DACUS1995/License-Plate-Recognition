{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms as T\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running training on [cuda]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pathlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import string\n",
    "from typing import Tuple\n",
    "import datetime\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Running training on [{device}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "WORKERS = 1\n",
    "EPOCHS = 20\n",
    "MAX_WORD_LENGTH = 10\n",
    "ALPHABET = string.ascii_letters + string.digits + \"_\" #blank char for CTC\n",
    "OUTPUT_SEQUENCE_LENGTH = 10\n",
    "OUTPUT_STEP_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, root_path, type=\"train\"):\n",
    "\t\tself.root_path = root_path\n",
    "\t\tself.type = type\n",
    "\t\tself.images_paths = list(pathlib.Path(self.root_path + \"./images\").glob('*.png'))\n",
    "\t\tself.transforms = {\n",
    "\t\t\t'train' : T.Compose([\n",
    "\t\t\t\t# T.Resize((40,200)),\n",
    "\t\t\t\tT.RandomRotation(20),\n",
    "\t\t\t\tT.GaussianBlur(3),\n",
    "\t\t\t\tT.ToTensor()\n",
    "\t\t\t]),\n",
    "\t\t\t'valid' : T.Compose([\n",
    "\t\t\t\tT.ToTensor()\n",
    "\t\t\t])\n",
    "\t\t}\n",
    "\t\tglobal ALPHABET\n",
    "\t\tself.alphabet = ALPHABET\n",
    "\t\tself.alphabet_size = len(self.alphabet)\n",
    "\t\tprint(f\"Alphabet size: {self.alphabet_size}\")\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timage_path = self.images_paths[idx]\n",
    "\t\tsample_name = str(image_path).split(os.sep)[-1].split(\".\")[0]\n",
    "\t\ttext_path = self.root_path + \"/transcripts/\" + str(int(sample_name) + 1) + \".txt\"\n",
    "\n",
    "\t\timage = Image.open(image_path).convert(\"RGB\")\n",
    "\t\twith open(text_path) as f:\n",
    "\t\t\ttext = f.read()\n",
    "\n",
    "\t\timage = self.transforms[self.type](image)\n",
    "\t\ttext_tensor = self.wordToTensor(text)\n",
    "\t\treturn image, (text_tensor, len(text), text)\n",
    "\t\t\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.images_paths)\n",
    "\n",
    "\tdef letterToIndex(self, letter):\n",
    "\t\treturn self.alphabet.find(letter)\n",
    "\n",
    "\tdef letterToTensor(self, letter):\n",
    "\t\ttensor = torch.zeros(1, n_letters)\n",
    "\t\ttensor[0][letterToIndex(letter)] = 1\n",
    "\t\treturn tensor\n",
    "\n",
    "\tdef wordToTensor(self, word):\n",
    "\t\ttensor = torch.zeros(MAX_WORD_LENGTH, self.alphabet_size)\n",
    "\t\t# for li, letter in enumerate(word):\n",
    "\t\t# \ttensor[li][self.letterToIndex(letter)] = 1\n",
    "\n",
    "\t\ttensor = torch.full((MAX_WORD_LENGTH,), len(ALPHABET) - 1)\n",
    "\t\t# tensor = torch.zeros(MAX_WORD_LENGTH)\n",
    "\t\tfor li, letter in enumerate(word):\n",
    "\t\t\ttensor[li] = self.letterToIndex(letter)\n",
    "\t\treturn tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "\tdef __init__(self, run_config):\n",
    "\t\tself._training_dataset = None\n",
    "\t\tself._validation_dataset = None\n",
    "\t\tself._run_config = run_config\n",
    "\n",
    "\t\tself._load_datasets()\n",
    "\t\t\n",
    "\tdef _load_datasets(self):\n",
    "\t\tself._training_dataset = CustomDataset(\"dataset/training\")\n",
    "\t\tself._validation_dataset = CustomDataset(\"dataset/validation\")\n",
    "\n",
    "\tdef get_data_loaders(self) -> Tuple[DataLoader]:\n",
    "\t\treturn (\n",
    "\t\t\tDataLoader(self._training_dataset, batch_size=self._run_config[\"batch_size\"], shuffle=True, pin_memory=True, drop_last=True), \n",
    "\t\t\tDataLoader(self._validation_dataset, batch_size=self._run_config[\"batch_size\"], shuffle=False, pin_memory=True, drop_last=True)\n",
    "\t\t)\n",
    "\n",
    "\tdef get_datasets(self) -> Tuple[Dataset]:\n",
    "\t\treturn self._training_dataset, self._validation_dataset\n",
    "\n",
    "\tdef get_datasets_sizes(self) -> Tuple[int]:\n",
    "\t\treturn len(self._training_dataset), len(self._validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Alphabet size: 63\nAlphabet size: 63\n"
     ]
    }
   ],
   "source": [
    "data_handler = DataHandler(run_config = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"workers\": WORKERS\n",
    "})\n",
    "train_loader, validation_loader = data_handler.get_data_loaders()\n",
    "training_dataset_size, validation_dataset_size = data_handler.get_datasets_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscribeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TranscribeModel, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\t\t\tnn.BatchNorm2d(16),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "\t\t\tnn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\t\t\tnn.BatchNorm2d(32),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=(2, 2)),\n",
    "\t\t\tnn.BatchNorm2d(64),\n",
    "\t\t\tnn.LeakyReLU(0.2, inplace=True)\n",
    "\t\t)\n",
    "        \n",
    "        self.linear_block1 = nn.Sequential(\n",
    "            nn.Linear(1536, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 630),\n",
    "        )\n",
    "\n",
    "        # self.rnn_block1 = nn.Sequential(\n",
    "        #     nn.LSTM(input_size=OUTPUT_STEP_SIZE * 64, hidden_size=len(ALPHABET), num_layers=2, batch_first=True, bidirectional=True)\n",
    "        # )\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv_block1(input)\n",
    "        # print(out.shape) #[128, 32, 10, 50]\n",
    "        # out = out.permute([0, 3, 2, 1])\n",
    "        # (B, S, ) \n",
    "        # out = out.reshape(out.size(0), out.size(1), -1)\n",
    "\n",
    "        # out, (_, _) = self.rnn_block1(out)\n",
    "\n",
    "        out = self.linear_block1(out.view(BATCH_SIZE, -1))\n",
    "        out = out.view(BATCH_SIZE, 10, len(ALPHABET))\n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TranscribeModel(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (linear_block1): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=630, bias=True)\n",
       "  )\n",
       "  (softmax): LogSoftmax(dim=2)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model = TranscribeModel()\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.0001, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-08, \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "# loss_criterion = nn.CTCLoss(blank=len(ALPHABET)-1, zero_infinity=False, reduction=\"mean\")\n",
    "loss_criterion = nn.NLLLoss()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=10, epochs=EPOCHS, anneal_strategy='linear')\n",
    "\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorToWord(tensor):\n",
    "\t# tensor = tensor[..., :63]\n",
    "\ttensor = tensor.permute([1, 0, 2])\n",
    "\tindices = torch.argmax(tensor, dim=2).tolist()\n",
    "\t\n",
    "\twords = []\n",
    "\tfor batch_idx in range(BATCH_SIZE):\n",
    "\t\tcur_word_indices = indices[batch_idx]\n",
    "\t\tcur_word = []\n",
    "\t\tlast_letter = None\n",
    "\t\tfor idx in range(OUTPUT_SEQUENCE_LENGTH):\n",
    "\t\t\tif ALPHABET[cur_word_indices[idx]] == ALPHABET[-1]:\n",
    "\t\t\t\tlast_letter = None\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\tif last_letter == None or (last_letter is not None and last_letter != cur_word_indices[idx]):\n",
    "\t\t\t\t\tcur_word.append(ALPHABET[cur_word_indices[idx]])\n",
    "\t\t\t\t\tlast_letter = cur_word_indices[idx]\n",
    "\t\t\t\t\tcontinue\n",
    "\t\twords.append(\"\".join(cur_word))\n",
    "\treturn words\n",
    "\n",
    "def tensorToWordSync(tensor):\n",
    "\tindices = torch.argmax(tensor, dim=2).tolist()\n",
    "\t\n",
    "\twords = []\n",
    "\tfor batch_idx in range(BATCH_SIZE):\n",
    "\t\tcur_word_indices = indices[batch_idx]\n",
    "\t\tcur_word = []\n",
    "\t\tlast_letter = None\n",
    "\t\tfor idx in range(OUTPUT_SEQUENCE_LENGTH):\n",
    "\t\t\tcur_word.append(ALPHABET[cur_word_indices[idx]])\n",
    "\n",
    "\t\twords.append(\"\".join(cur_word))\n",
    "\treturn words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(string_one, string_two):\n",
    "    dist = np.zeros((len(string_one) + 1, len(string_two) + 1))\n",
    "    dist[1:, 0] = [i + 1 for i in range(len(string_one))]\n",
    "    dist[0, 1:] = [i + 1 for i in range(len(string_two))]\n",
    "\n",
    "    for row in range(1, len(string_one) + 1):\n",
    "        for col in range(1, len(string_two) + 1):\n",
    "            gain = 1\n",
    "            if string_one[row - 1] == string_two[col -1]:\n",
    "                dist[row, col] = dist[row - 1, col -1]\n",
    "            else:\n",
    "                dist[row, col] = gain + min(dist[row - 1, col], dist[row, col - 1], dist[row - 1, col - 1])\n",
    "    \n",
    "    return dist[-1,-1]\n",
    "\n",
    "def batchLevenshteinDistance(arr_one, arr_two):\n",
    "    cumulative_distance = 0\n",
    "    for idx in range(len(arr_one)):\n",
    "        cumulative_distance += levenshteinDistance(arr_one[idx], arr_two[idx])\n",
    "    return cumulative_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 2,  5,  8,  7,  8,  3,  3,  2,  3,  4, 10,  2,  1,  7,  4,  4,  1,  6,\n         3,  1,  5,  8,  9,  7,  3,  1,  9,  2,  6,  9,  3,  8,  7,  3, 10,  1,\n         5, 10,  6,  5,  7,  1,  4,  8, 10,  7,  7,  2,  5,  3,  4,  9,  8,  2,\n         5,  7,  6,  4,  9,  7,  5,  6,  8,  5])\n"
     ]
    }
   ],
   "source": [
    "image, (label_tensor, text_length, label_text) = iter(train_loader).next()\n",
    "image, label_tensor = image.to(device), label_tensor.to(device)\n",
    "output = model(image)\n",
    "print(text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 63])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>>>>>> label_text <<<<<<<\n['ik', '4rhXn', 'PB3zCbGT', 'xe2eW10', 'Ut4G0uua', 'xZf', 'SU6', 'HJ', 'nFS', 'iYcy', 'vAxt9ajHtU', 'cZ', 'P', 'dvW64HK', 'BfTg', 'egcK', 'r', 'yKNiUD', 'bOW', 'M', 'RNSbN', 'bfZoak1g', 'fqyDk9cC7', 'NQQWIZ2', 'm0j', 'f', 'bfl2mKpGJ', 'Gy', 'AxGQju', 'Fk2QkYZxu', 'UnG', 'MtSEqwCx', 'ILTDgd9', 'BPR', 'ukirCOsylM', 's', 'pGXPK', 'dRpznLKvSB', 'CIdaSu', 'aOkEr', '1yuNT4f', 'U', 'XBy9', 'CK5HJWil', 'JjlOcV9qMN', 'qocGOMS', 'AeEuIEQ', 'JO', 'I8cBd', 'tio', 'X2bn', '93GhZkCXr', 'B2gonagN', '2A', 'XYAZJ', 'opghYSM', 'z5r4QQ', 'zdAw', 'D71MLSeAd', 'oX51Vxh', 'NlMbz', 'uZ1p39', 'qU285CGw', 'BOk5U']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hl________',\n",
       " 'ajX0______',\n",
       " 'bdgs1bAT__',\n",
       " 'xcZgYVT___',\n",
       " 'UMfR0wuS__',\n",
       " 'xZ________',\n",
       " 'VSk_______',\n",
       " 'i1________',\n",
       " 'wFX_______',\n",
       " 'yVZ_______',\n",
       " 'vAxwegjHt_',\n",
       " 'cz________',\n",
       " 'P_________',\n",
       " 'qNWReOQ___',\n",
       " 'BYTg______',\n",
       " 'axX_______',\n",
       " 'P_________',\n",
       " 'kQOINJ____',\n",
       " 'gOW_______',\n",
       " 'Mt________',\n",
       " 'Ufe5NV____',\n",
       " 'bSgaA3____',\n",
       " 'MdjDbxcC7_',\n",
       " 'KQBWNQCT__',\n",
       " 'wdj_______',\n",
       " 'e_________',\n",
       " 'bfXomKpGC_',\n",
       " 'Gy________',\n",
       " 'XXGXM_____',\n",
       " 'FxE3gTT9u_',\n",
       " 'yne_______',\n",
       " '8BEEgwCx__',\n",
       " 'XKT2pB9___',\n",
       " 'BFB_______',\n",
       " 'uMcZ7wmyM_',\n",
       " 'e_________',\n",
       " 'hSZZA_____',\n",
       " 'dDBmaLJJSB',\n",
       " 'Cmmk9_____',\n",
       " 'aOpE______',\n",
       " 'Vr9TT4____',\n",
       " 'U_________',\n",
       " 'iBjq______',\n",
       " 'ODVHAJiw__',\n",
       " '2yFFOnvWKN',\n",
       " '64K41MJ___',\n",
       " 'AeEk9GX___',\n",
       " 'JD________',\n",
       " 'HpEg______',\n",
       " 'Kp________',\n",
       " 'XSgn______',\n",
       " '9TQkSbCO__',\n",
       " 'ScEmmkg___',\n",
       " 'ZA________',\n",
       " 'lrXZ2_____',\n",
       " '8egY1Ul___',\n",
       " 'cBoGQ_____',\n",
       " 'ERzw______',\n",
       " 'RY1ML5ew4_',\n",
       " 'bXZY73____',\n",
       " 'Amnbs_____',\n",
       " 'nZJg3K____',\n",
       " '8UzS9SGQI_',\n",
       " 'XBk5A_____']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "output.shape\n",
    "out = output[..., :63]\n",
    "# torch.argmax(out, dim=2)\n",
    "print(\">>>>>>> label_text <<<<<<<\")\n",
    "print(label_text)\n",
    "\n",
    "# print(\">>>>>>> label_tensor <<<<<<<\")\n",
    "# print(label_tensor)\n",
    "\n",
    "# print(\">>>>>>> output <<<<<<<<\")\n",
    "# print(output)\n",
    "\n",
    "tensorToWordSync(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/20\n----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [1] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39fcd709794a496aa2f49c9af9c79fc1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.4403 | Dist: 9.8790\n",
      "Evaluation step => Loss: 2.2286 | Dist 9.2258\n",
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [2] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85841db0dc9b47ed8e37c3af779bd4fc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3667 | Dist: 9.8240\n",
      "Evaluation step => Loss: 2.1910 | Dist 9.1774\n",
      "Epoch 2/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [3] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d80422e15514a56b02f3afbd9d0083d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3393 | Dist: 9.7768\n",
      "Evaluation step => Loss: 2.1735 | Dist 9.1629\n",
      "Epoch 3/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [4] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13cb9f0a32a84eef92987bc8664fabc4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3246 | Dist: 9.7544\n",
      "Evaluation step => Loss: 2.1693 | Dist 9.1565\n",
      "Epoch 4/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [5] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fcb80b86ec34f8bb19953d1eca5131d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3190 | Dist: 9.7455\n",
      "Evaluation step => Loss: 2.1621 | Dist 9.1500\n",
      "Epoch 5/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [6] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58ca748e18524cf9a2adc04f8f1f850f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3122 | Dist: 9.7337\n",
      "Evaluation step => Loss: 2.1590 | Dist 9.1516\n",
      "Epoch 6/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [7] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32f71d1c81a4410686b26b9deca8e8b6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3056 | Dist: 9.7248\n",
      "Evaluation step => Loss: 2.1589 | Dist 9.1435\n",
      "Epoch 7/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [8] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0f2af546c0f497bac4ae41a09d99c56"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.3016 | Dist: 9.7194\n",
      "Evaluation step => Loss: 2.1579 | Dist 9.1274\n",
      "Epoch 8/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [9] progress', max=96.0, style=ProgressStyle(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c0e486ba2d64cb9a0446a31bfb8898e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.2923 | Dist: 9.7006\n",
      "Evaluation step => Loss: 2.1540 | Dist 9.1290\n",
      "Epoch 9/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [10] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad82d2e1a45a46bc952fdfd216cacaa6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.2801 | Dist: 9.6784\n",
      "Evaluation step => Loss: 2.1481 | Dist 9.1097\n",
      "Epoch 10/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [11] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ceb2a588be14e22b413d185002626ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.2620 | Dist: 9.6468\n",
      "Evaluation step => Loss: 2.1357 | Dist 9.0871\n",
      "Epoch 11/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [12] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "211af0c2959f4715a8677012764cc315"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.2215 | Dist: 9.5889\n",
      "Evaluation step => Loss: 2.1027 | Dist 9.0484\n",
      "Epoch 12/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [13] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7933d194b1bd4b18ba8d4695281bb126"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.1688 | Dist: 9.5135\n",
      "Evaluation step => Loss: 2.0664 | Dist 8.9887\n",
      "Epoch 13/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [14] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "208ad44fc7d443afa9c71fcd01f40504"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.0969 | Dist: 9.4008\n",
      "Evaluation step => Loss: 2.0474 | Dist 8.9435\n",
      "Epoch 14/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [15] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7efcfa31ebd4c86af3e203a5c18717d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 2.0200 | Dist: 9.2844\n",
      "Evaluation step => Loss: 1.9892 | Dist 8.8710\n",
      "Epoch 15/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [16] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "209db314f2a14b39ba00adab03014301"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 1.9333 | Dist: 9.1565\n",
      "Evaluation step => Loss: 1.9493 | Dist 8.7645\n",
      "Epoch 16/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [17] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04d639fa229f47ebae0fe0a2e647c023"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 1.8555 | Dist: 9.0213\n",
      "Evaluation step => Loss: 1.9024 | Dist 8.7065\n",
      "Epoch 17/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [18] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe420a604afb41c7952e0f9749207f4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 1.7763 | Dist: 8.8635\n",
      "Evaluation step => Loss: 1.8843 | Dist 8.6984\n",
      "Epoch 18/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [19] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c53c04e6bf346d39b81c5bd67133315"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 1.6979 | Dist: 8.7240\n",
      "Evaluation step => Loss: 1.8390 | Dist 8.5177\n",
      "Epoch 19/20\n",
      "----------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epoch [20] progress', max=96.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d4986c893744149874ffb269a38d1ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training step => Loss: 1.6224 | Dist: 8.5813\n",
      "Evaluation step => Loss: 1.8168 | Dist 8.4952\n",
      "Training complete in 3m 3s\n",
      "Best (so far) validation Acc: 0.000000\n",
      "----------\n",
      "### Final results ###\n",
      "\n",
      "Best validation Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "\tprint('Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "\tprint('-' * 10)\n",
    "\n",
    "\t########### Training step ###########\n",
    "\tmodel = model.train()\n",
    "\ttraining_loss = []\n",
    "\trunning_loss = 0.0\n",
    "\trunning_corrects = 0\n",
    "\t\t\t\n",
    "\tfor i, data in enumerate(tqdm(train_loader, desc=f\"Epoch [{epoch + 1}] progress\")):\n",
    "\n",
    "\t\tx_batch, (label_batch, label_length, label_text) = data\n",
    "\t\tx_batch, label_batch, label_length = x_batch.to(device), label_batch.to(device), label_length.to(device)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(x_batch)\n",
    "\t\toutputs_permuted = outputs.permute((0, 2, 1))\n",
    "\n",
    "\t\t# loss = loss_criterion(outputs, label_batch, torch.full((BATCH_SIZE,), OUTPUT_SEQUENCE_LENGTH).to(device), label_length)\n",
    "\t\tloss = loss_criterion(outputs_permuted, label_batch)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# statistics\n",
    "\t\trunning_loss += loss.item() * x_batch.size(0)\n",
    "\t\tpredictions = tensorToWordSync(outputs)\n",
    "\t\trunning_corrects += batchLevenshteinDistance(predictions, label_text)\n",
    "\t\ttraining_loss.append(loss.item())\n",
    "\n",
    "\tepoch_loss = running_loss / training_dataset_size\n",
    "\tepoch_acc = running_corrects / training_dataset_size\n",
    "\n",
    "\t# tensorboard logging\n",
    "\twriter.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "\n",
    "\tprint('Training step => Loss: {:.4f} | Dist: {:.4f}'.format(\n",
    "\t\tepoch_loss, epoch_acc\n",
    "\t))\n",
    "\n",
    "\tscheduler.step()\n",
    "\n",
    "\n",
    "\t########### Validation step ###########\n",
    "\tmodel = model.eval()\n",
    "\tvalidation_loss = []\n",
    "\trunning_loss = 0.0\n",
    "\trunning_corrects = 0\n",
    "\n",
    "\tfor i, data in enumerate(validation_loader):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tx_batch, (label_batch, label_length, label_text) = data\n",
    "\t\t\tx_batch, label_batch, label_length = x_batch.to(device), label_batch.to(device), label_length.to(device)\n",
    "\n",
    "\t\t\toutputs = model(x_batch)\n",
    "\t\t\toutputs_permuted = outputs.permute((0, 2, 1))\n",
    "\t\t\t# loss = loss_criterion(outputs, label_batch, torch.full((BATCH_SIZE,), OUTPUT_SEQUENCE_LENGTH).to(device), label_length)\n",
    "\t\t\tloss = loss_criterion(outputs_permuted, label_batch)\n",
    "\n",
    "\t\t\trunning_loss += loss.item() * x_batch.size(0)\n",
    "\t\t\t\n",
    "\t\t\tpredictions = tensorToWordSync(outputs)\n",
    "\t\t\trunning_corrects += batchLevenshteinDistance(predictions, label_text)\n",
    "\t\t\tvalidation_loss.append(loss.item())\n",
    "\t\t\t\n",
    "\tepoch_loss = running_loss / validation_dataset_size\n",
    "\tepoch_acc = running_corrects / validation_dataset_size\n",
    "\n",
    "\t# tensorboard logging\n",
    "\twriter.add_scalar(\"Loss/validation\", epoch_loss, epoch)\n",
    "\n",
    "\tprint('Evaluation step => Loss: {:.4f} | Dist {:.4f}'.format(\n",
    "\t\tepoch_loss, epoch_acc\n",
    "\t))\n",
    "\tbest_acc = 0\n",
    "\t#Save the best model based on accuracy\n",
    "\tif True:\n",
    "\t\tbest_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\t#Checkpoint\n",
    "\ttorch.save({\n",
    "\t\t\"epoch\": epoch,\n",
    "\t\t\"model_state_dict\": model.state_dict(),\n",
    "\t\t\"optimizer_state_dict\": optimizer.state_dict()\n",
    "\t}, \"./checkpoints/ckp.pt\")\n",
    "\n",
    "\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "\ttime_elapsed // 60, time_elapsed % 60\n",
    "))\n",
    "print('Best (so far) validation Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "print('-' * 10)\n",
    "print('### Final results ###\\n')\n",
    "print('Best validation Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "97c67d8e0382c833d1d7ff2aaf3d36bcbf66720dd18abf32e81be90b4a114af6"
    }
   }
  },
  "language_info": {
   "name": "",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}